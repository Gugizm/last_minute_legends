services:
  spark-streaming:
    build: .
    container_name: spark-streaming
    volumes:
      - .:/app
    depends_on:
      - spark-master
      - kafka
    env_file:
      - .env
    networks:
      - kafka_network
    command: >
      spark-submit --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.4.0 /app/services/spark_streaming_processor.py

  spark-batch:
    build: .
    container_name: spark-batch
    volumes:
      - .:/app
    depends_on:
      - spark-master
      - kafka
    env_file:
      - .env
    networks:
      - kafka_network
    command: >
      sh -c "python3 services/spark_batch_processor.py"

  kafka:
    image: confluentinc/cp-kafka:latest
    container_name: kafka
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_MIN_INSYNC_REPLICAS: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 100
      KAFKA_CONFLUENT_SUPPORT_METRICS_ENABLE: "false"
      KAFKA_LOG_DIRS: /var/lib/kafka/data
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
      KAFKA_DELETE_TOPIC_ENABLE: "true"
    networks:
      - kafka_network

  spark-master:
    image: bitnami/spark:latest
    container_name: spark-master
    ports:
      - "8080:8080"
    environment:
      - SPARK_MODE=master
    networks:
      - kafka_network

  spark-worker:
    image: bitnami/spark:latest
    container_name: spark-worker
    depends_on:
      - spark-master
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
    networks:
      - kafka_network

networks:
  kafka_network:
