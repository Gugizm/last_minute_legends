services:
  spark-batch:
    build: .
    container_name: spark-batch
    volumes:
      - .:/app
    depends_on:
      - spark-master
      - kafka
    env_file:
      - .env
    networks:
      - kafka_network
    command: >
      sh -c "python3 services/spark_batch_processor.py"

  spark-streaming:
    build: .
    container_name: spark-streaming
    volumes:
      - .:/app
    depends_on:
      - spark-master
      - kafka
    env_file:
      - .env
    networks:
      - kafka_network
    command: >
      sh -c "python3 services/spark_streaming_processor.py"

  kafka:
    image: confluentinc/cp-kafka:latest
    container_name: kafka
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_ZOOKEEPER_CONNECT: ""
      KAFKA_CONFLUENT_SUPPORT_METRICS_ENABLE: "false"
      KAFKA_SCHEMA_REGISTRY_URL: ${SCHEMA_REGISTRY_URL}
    networks:
      - kafka_network

  spark-master:
    image: bitnami/spark:latest
    container_name: spark-master
    ports:
      - "8080:8080"
    environment:
      - SPARK_MODE=master
    networks:
      - kafka_network

  spark-worker:
    image: bitnami/spark:latest
    container_name: spark-worker
    depends_on:
      - spark-master
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
    networks:
      - kafka_network

  airflow:
    image: apache/airflow:latest
    container_name: airflow
    ports:
      - "8081:8080"
    environment:
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
    depends_on:
      - spark-master
    networks:
      - kafka_network

networks:
  kafka_network:
